{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction and problem statement\n",
    "\n",
    "Finding a place to live is a big challenge, especially in big cities. Not only it is time consuming, but compare them whn we narrow down our choice to a few is another challenge. For families with children the best school district is priority, for single workers, being closer to a subway is a plus.\n",
    "\n",
    "In this notebook, we will:\n",
    "- Scrape the information from an apartment listing data \n",
    "- Clean and transform the data\n",
    "- Analyze and visualize the data\n",
    "- Forcasting the price for apartment for different neigborhoods\n",
    "\n",
    "#### Scraping Data from the web\n",
    "For this exercise, we will be using RentHopsite(http://www.renthop.com). We will focus our energy only on apartments in NYC and neighorhoods.\n",
    "![title](img/homes_apartment.jpg)\n",
    "\n",
    "Above is the overview of the site. We will be retrieving the informations below:\n",
    "- Address\n",
    "- Number of beds and number of baths\n",
    "- The listing price\n",
    "- The property type (Home, Townhome, Apts)\n",
    "- Zip code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding libraries we will be using\n",
    "\n",
    "For scraping we will be using **requests** to pull down listings and use **BeautifulSoup** to extract different attributes. There are two populars way to navigate  HTML structures known as **Document Object Models (DOMs)** XPath and CSS Selectors. We will be using the CSS selectors, which is a pattern language built to work with HTML and identify elements using a combination of element type, class,and ID properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import requests \n",
    "import matplotlib.pyplot as plt \n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1- getting the whole page to scrape\n",
    "  Fist of all, let us define a function call get_url that will allow us to get the Document Object Model for a given page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url (url):\n",
    "    try:\n",
    "        response = requests.get(url).content\n",
    "        return BeautifulSoup(response,'html.parser')\n",
    "    except requests.exceptions.RequestException as e: \n",
    "        print(\"Something when wrong !\")\n",
    "        raise SystemExit(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the whole page\n",
    "soup=get_url('https://www.renthop.com/nyc/manhattan-apartments')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- getting the list of the all listings to scrape\n",
    "After getting the HTML for the whole page, we are going to write another fuction to get the area that has only all the properties that we are interested in.\n",
    "Using Chrome developer console, we see that the main text is within a **div** tag with *id=search-results-list* and each listing is in another **div** tag with *class=search-listing*. therefore, we will be getting all *search-listing*.\n",
    "As we can see, each page has 72 listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "APARTMENTS='div.search-listing'\n",
    "\n",
    "listing_divs = soup.select(APARTMENTS)#[0].select_one(APARTMENTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_listings(soup, locator):\n",
    "    '''\n",
    "    our function takes a soup object and a locator and return the\n",
    "     list of all individual listings.\n",
    "    '''\n",
    "    return soup.select(locator) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3- processing each listing to get individual attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "LISTINGID_LOCATOR = 'div.search-listing'\n",
    "LINK_LOCATOR = 'div.search-listing-details a'\n",
    "NAME_LOCATOR = 'div.search-listing-details div.font-size-9.overflow-ellipsis'\n",
    "BEDS_LOCATOR = 'div.search-listing div.search-results-bed' \n",
    "BATH_LOCATOR = 'div.search-listing div.search-results-bath' \n",
    "TYPE_LOCATOR = 'div.search-listing div.d-block.font-gray-1.font-size-9'\n",
    "DATE_LOCATOR = 'div.search-listing-details>div.col-12>div.font-size-9'\n",
    "DESCRIPTION_LOCATOR = 'div.px-3.px-lg-0>div.font-size-10'\n",
    "page=get_all_listings(soup,locator=APARTMENTS)\n",
    "page_details=get_all_listings(soup,locator=LINK_LOCATOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "listingID = page[0].attrs['data-id']\n",
    "longitude = page[0].attrs['data-longitude']\n",
    "latitude  = page[0].attrs['data-latitude']\n",
    "listPrice = page[0].attrs['data-price']\n",
    "down_payment = page[0].attrs['data-min-downpay-pct']\n",
    "propertyTax = page[0].attrs['data-tax']\n",
    "address = page[0].attrs['data-listing-name']\n",
    "link=page_details[0].attrs['href']#.select_one()\n",
    "name_area = get_all_listings(soup,locator=NAME_LOCATOR)[0].text\n",
    "beds=get_all_listings(soup,locator=BEDS_LOCATOR)[0].text.split('\\n')\n",
    "bed=[b for b in beds if len(b)>0 and b.isnumeric()][0]\n",
    "\n",
    "baths=get_all_listings(soup,locator=BATH_LOCATOR)[0].text.split('\\n')\n",
    "bath=[b for b in baths if len(b)>0 and b.isnumeric()][0]\n",
    "house_type=get_all_listings(soup,locator=TYPE_LOCATOR)[0].text.split(',')[0].strip()\n",
    "date_published=get_all_listings(soup,locator=DATE_LOCATOR)[0].text.strip()[7:]\n",
    "\n",
    "soup_details=get_url(link)\n",
    "description=get_all_listings(soup_details,locator=DESCRIPTION_LOCATOR)[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(listPrice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling out the individual data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "href=listing_divs[0].select('a[id*=title]')[0]['href']\n",
    "addy=listing_divs[0].select('a[id*=title]')[0].text\n",
    "hood=listing_divs[0].select('div[id*=hood]')[0].string.replace('\\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting other elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$2,600', '2_Bed', '1_Bath']\n"
     ]
    }
   ],
   "source": [
    "listing_specs =listing_divs[0].select('table[id*=info] tr')\n",
    "for spec in listing_specs:\n",
    "    spec_data=spec.text.strip().replace(' ','_').split()\n",
    "    print(spec_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(listing_divs):\n",
    "    listing_list=[]\n",
    "    for idx in range(len(listing_divs)):\n",
    "        indv_listing=[]\n",
    "        current_listing=listing_divs[idx]\n",
    "        href=listing_divs[0].select('a[id*=title]')[0]['href']\n",
    "        addy=listing_divs[0].select('a[id*=title]')[0].text.replace(',','_')\n",
    "        hood=listing_divs[0].select('div[id*=hood]')[0].string.replace('\\n','').replace(',','_')\n",
    "\n",
    "        indv_listing.append(href)\n",
    "        indv_listing.append(addy)\n",
    "        indv_listing.append(hood)\n",
    "\n",
    "        listing_specs=current_listing.select('table[id*=info] tr')\n",
    "        for spec in listing_specs:\n",
    "            try:\n",
    "                indv_listing.extend(spec.text.strip().replace(' ','_').replace(',','_').split())\n",
    "                indv_listing=[x for x in indv_listing if len(x.strip())!=0]\n",
    "            except:\n",
    "                indv_listing.extend(np.nan)\n",
    "        listing_list.append(indv_listing)\n",
    "    return listing_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=1&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=2&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=3&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=4&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=5&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=6&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=7&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=8&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=9&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=10&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=11&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=12&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=13&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=14&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=15&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=16&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=17&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=18&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=19&sort=hopscore&q=&search=0\n",
      "https://www.renthop.com/search/nyc?max_price=50000&min_price=20&sort=hopscore&q=&search=0\n"
     ]
    }
   ],
   "source": [
    "all_pages_parsed=[]\n",
    "for i in range(1,21):\n",
    "    target_page=f\"https://www.renthop.com/search/nyc?max_price=50000&min_price={i}&sort=hopscore&q=&search=0\"\n",
    "    print(target_page)\n",
    "    r=requests.get(target_page).content\n",
    "    \n",
    "    soup=BeautifulSoup(r,'html5lib')\n",
    "    listing_divs=soup.select('div[class*=search-info]')\n",
    "    one_page_parsed =parse_data(listing_divs)\n",
    "    all_pages_parsed.extend(one_page_parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['https://www.renthop.com/listings/e20-street/na/15733028',\n",
       "  'E20 street',\n",
       "  'Stuyvesant Town - Peter Cooper Village_ Midtown Manhattan_ Manhattan',\n",
       "  '$4_831',\n",
       "  '3_Bed',\n",
       "  '_1_Bath'],\n",
       " ['https://www.renthop.com/listings/e20-street/na/15733028',\n",
       "  'E20 street',\n",
       "  'Stuyvesant Town - Peter Cooper Village_ Midtown Manhattan_ Manhattan',\n",
       "  '$5_600',\n",
       "  '4_Bed',\n",
       "  '3_Bath'],\n",
       " ['https://www.renthop.com/listings/e20-street/na/15733028',\n",
       "  'E20 street',\n",
       "  'Stuyvesant Town - Peter Cooper Village_ Midtown Manhattan_ Manhattan',\n",
       "  '$2_450',\n",
       "  '1_Bed',\n",
       "  '1_Bath']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pages_parsed[:3]\n",
    "#df = pd.DataFrame(all_pages_parsed, columns=['url', 'address', 'neighborhood', 'rent', 'beds', 'baths','last']) \n",
    "#del df['last']\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
